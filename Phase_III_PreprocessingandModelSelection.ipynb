{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase III: Preprocessing & Model Selection\n",
    "\n",
    "In order to find the best modeling method for the question at hand, I fit four models to the testing data using Gridsearch to find the best hyperparameters:\n",
    "\n",
    "- [Logistic Regression](#Logistic-Regression)\n",
    "- [Random Forest Classifier](#Random-Forest)\n",
    "- [Multinomial Naive Bayes](#Naive-Bayes)\n",
    "- [Bagging Classifier](#Bagging-Classifier)\n",
    "\n",
    "I decided to use only the text data from the **'title'** column of the data set as the X variable. I chose to model the data in this way so that we could easily interpret the performance of each model. In other words, limiting the predictors to a single text feature forces the model to make predictions based solely on text content. Since the goal here is to see how well a computer can destinguish between substantiated and unsubstantiated claims, I felt it appropriate to isolate text as the sole predictor of class.\n",
    "\n",
    "Logistic Regression and Random Forest had the strongest initial performance, so I decided to proceed with these two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Importing Packages & Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1916, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Datasets/Final_Reddit_Dataset_CLEAN.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preprocessing & Gridsearching Hyperparameters\n",
    "\n",
    "Using pipelines in conjunction with GridSearch allows for easy preprocessing, model tuning, and model fitting, all in the same step. After setting the predictor and target variables, running a train/test split, and instanitating the models, I built out pipelines for each of the following:\n",
    "\n",
    "- Logistic Regression\n",
    "- Random Forest Classifier\n",
    "- Multinomial Naive Bayes\n",
    "- Bagging Classifier\n",
    "\n",
    "I fit each model to the training data twice, once using the Count Vectorizer, and once using the TF-IDF vectorizer. I proceeded to manually adjust the parameter grid for each pipeline until I reached an optimal train and test score. You'll notice that certain parameters below have been commented out - these are settings that were tested, but that ultimately did not improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['subreddit_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tf = TfidfVectorizer()\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "nb = MultinomialNB()\n",
    "bg = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "##### Gridsearching with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.7049408489909533\n",
      "GridSearch Best Params: {'cv__max_features': 5000, 'cv__ngram_range': (1, 5), 'cv__stop_words': None, 'lr__C': 0.5, 'lr__class_weight': None, 'lr__penalty': 'l2'}\n",
      "\n",
      "Train Score: 0.9693806541405706\n",
      "Test Score: 0.6993736951983298\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "params={\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "    'cv__max_features': [None, 4000, 5000, 6000], #3000\n",
    "    'cv__ngram_range': [(1, 3), (1, 4), (1, 5), (1, 6)], #(1, 1), (1, 2), (1, 3)\n",
    "    #'cv__max_df': [2, 5, 7],\n",
    "    #'cv__min_df': [1, 2, 3],\n",
    "    'lr__class_weight': [None], # {1: .45}\n",
    "    'lr__penalty': ['l2'], # 'l1'\n",
    "    'lr__C': [.5] # 1.0, .01\n",
    "}\n",
    "gs_lr_cv = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_lr_cv.fit(X_train, y_train);\n",
    "\n",
    "print('GridSearch Best Score:', gs_lr_cv.best_score_)\n",
    "print('GridSearch Best Params:',gs_lr_cv.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_lr_cv.score(X_train, y_train))\n",
    "print('Test Score:', gs_lr_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gridsearching with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.7042449547668754\n",
      "GridSearch Best Params: {'lr__C': 0.5, 'lr__class_weight': None, 'lr__penalty': 'l2', 'tf__max_features': None, 'tf__ngram_range': (1, 2), 'tf__stop_words': None}\n",
      "\n",
      "Train Score: 0.9227557411273486\n",
      "Test Score: 0.7265135699373695\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tf', tf),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "params={\n",
    "    'tf__stop_words': [None, 'english'],\n",
    "    'tf__max_features': [None, 2000, 3000, 4000], # 5000\n",
    "    'tf__ngram_range': [(1, 1), (1, 2), (1, 3)], # (1, 5), (1, 4)\n",
    "    #'tf__max_df': [2, 5, 7],\n",
    "    #'tf__min_df': [1, 2, 3],\n",
    "    #'tf__smooth_idf': [True, False],\n",
    "    'lr__class_weight': [None, {1: .45}],\n",
    "    'lr__penalty': ['l2', 'l1'],\n",
    "    'lr__C': [1.0, .5, .01]\n",
    "}\n",
    "gs_lr_tf = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_lr_tf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearch Best Score:', gs_lr_tf.best_score_)\n",
    "print('GridSearch Best Params:',gs_lr_tf.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_lr_tf.score(X_train, y_train))\n",
    "print('Test Score:', gs_lr_tf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearching with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.7021572720946416\n",
      "GridSearch Best Params: {'cv__max_features': 5000, 'cv__ngram_range': (1, 5), 'cv__stop_words': None, 'rf__criterion': 'entropy', 'rf__max_depth': None, 'rf__max_features': 'auto', 'rf__n_estimators': 150}\n",
      "\n",
      "Train Score: 0.9937369519832986\n",
      "Test Score: 0.7202505219206681\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "    'cv__max_features': [5000, 6000], # 3000, None, 4000, \n",
    "    'cv__ngram_range': [(1, 5)], #(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)\n",
    "    #'cv__max_df': [2, 5, 7],\n",
    "    #'cv__min_df': [1, 2, 3],\n",
    "    'rf__n_estimators': [150, 250], # 10, 50, 100,\n",
    "    'rf__criterion': ['entropy'], # 'gini'\n",
    "    'rf__max_depth': [None], # 2, 4, 1, 3\n",
    "    'rf__max_features': ['auto'] # , 1.0, .5\n",
    "}\n",
    "\n",
    "gs_rf_cv = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_rf_cv.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearch Best Score:', gs_rf_cv.best_score_)\n",
    "print('GridSearch Best Params:',gs_rf_cv.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_rf_cv.score(X_train, y_train))\n",
    "print('Test Score:', gs_rf_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearching with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.6896311760612387\n",
      "GridSearch Best Params: {'rf__criterion': 'gini', 'rf__max_depth': None, 'rf__max_features': 'auto', 'rf__n_estimators': 50, 'tf__max_features': 4000, 'tf__ngram_range': (1, 3), 'tf__smooth_idf': True, 'tf__stop_words': None}\n",
      "\n",
      "Train Score: 0.9930410577592206\n",
      "Test Score: 0.7202505219206681\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tf', tf),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "params={\n",
    "    'tf__stop_words': [None, 'english'],\n",
    "    'tf__max_features': [3000, 4000, 5000],\n",
    "    'tf__ngram_range': [(1, 2), (1, 3), (1, 4)], # (1, 1), (1, 5)\n",
    "    'tf__smooth_idf': [True, False],\n",
    "    'rf__n_estimators': [10, 50], # 100\n",
    "    'rf__criterion': ['gini'], # 'entropy'\n",
    "    'rf__max_depth': [None, 1, 3], # 2, 4\n",
    "    'rf__max_features': ['auto'] #1.0, .5\n",
    "}\n",
    "gs_rf_tf = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_rf_tf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearch Best Score:', gs_rf_tf.best_score_)\n",
    "print('GridSearch Best Params:',gs_rf_tf.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_rf_tf.score(X_train, y_train))\n",
    "print('Test Score:', gs_rf_tf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "#### Gridsearching with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.6638830897703549\n",
      "GridSearch Best Params: {'cv__max_features': None, 'cv__ngram_range': (1, 3), 'cv__stop_words': None, 'nb__alpha': 0, 'nb__fit_prior': True}\n",
      "\n",
      "Train Score: 0.9916492693110647\n",
      "Test Score: 0.6638830897703549\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('nb', nb)\n",
    "])\n",
    "\n",
    "params={\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "    'cv__max_features': [None, ], #3000, 6000, 3000, 4000, 5000\n",
    "    'cv__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)], # (1, 5), (1, 6), (1, 7)\n",
    "    #'cv__max_df': [5, 7], # 2\n",
    "    #'cv__min_df': [1, 2, 3],\n",
    "    'nb__alpha': [0], # 2, 5, .5, 1\n",
    "    'nb__fit_prior': [True, False]\n",
    "}\n",
    "gs_nb_cv = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_nb_cv.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearch Best Score:', gs_nb_cv.best_score_)\n",
    "print('GridSearch Best Params:',gs_nb_cv.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_nb_cv.score(X_train, y_train))\n",
    "print('Test Score:', gs_nb_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearching with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.6868475991649269\n",
      "GridSearch Best Params: {'tf__max_features': None, 'tf__ngram_range': (1, 2), 'tf__smooth_idf': True, 'tf__stop_words': None}\n",
      "\n",
      "Train Score: 0.9909533750869868\n",
      "Test Score: 0.7118997912317327\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tf', tf),\n",
    "    ('nb', nb)\n",
    "])\n",
    "\n",
    "params={\n",
    "    'tf__stop_words': [None, 'english'], # \n",
    "    'tf__max_features': [None, 2000, 3000, 4000], # 5000\n",
    "    'tf__ngram_range': [(1, 2), (1, 3), (1, 4)], # (1, 1), (1, 5)\n",
    "    'tf__smooth_idf': [True, False],\n",
    "    #'nb__alpha': [1, 2],\n",
    "    #'nb__fit_prior': [True, False]\n",
    "}\n",
    "gs_nb_tf = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_nb_tf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearch Best Score:', gs_nb_tf.best_score_)\n",
    "print('GridSearch Best Params:',gs_nb_tf.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_nb_tf.score(X_train, y_train))\n",
    "print('Test Score:', gs_nb_tf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bagging Classifier\n",
    "\n",
    "##### Gridsearching with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.6965901183020181\n",
      "GridSearch Best Params: {'bg__bootstrap_features': True, 'bg__n_estimators': 50, 'cv__max_features': 5000, 'cv__ngram_range': (1, 5), 'cv__stop_words': None}\n",
      "\n",
      "Train Score: 0.9930410577592206\n",
      "Test Score: 0.7014613778705637\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('bg', bg)\n",
    "])\n",
    "\n",
    "params={\n",
    "    'cv__stop_words': [None], #\n",
    "    'cv__max_features': [5000], # 3000, None, 4000, 6000\n",
    "    'cv__ngram_range': [(1, 4), (1, 5)], #(1, 1), (1, 2), (1, 3), , (1, 6)\n",
    "    #'cv__max_df': [2, 5, 7],\n",
    "    #'cv__min_df': [1, 2, 3],\n",
    "    'bg__n_estimators': [50, 75], # 5, 10\n",
    "    'bg__bootstrap_features': [True] # False\n",
    "}\n",
    "gs_bg_cv = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_bg_cv.fit(X_train, y_train);\n",
    "\n",
    "print('GridSearch Best Score:', gs_bg_cv.best_score_)\n",
    "print('GridSearch Best Params:',gs_bg_cv.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_bg_cv.score(X_train, y_train))\n",
    "print('Test Score:', gs_bg_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gridsearching with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Score: 0.6805845511482255\n",
      "GridSearch Best Params: {'bg__bootstrap_features': True, 'bg__n_estimators': 50, 'tf__max_features': 4000, 'tf__ngram_range': (1, 1), 'tf__stop_words': None}\n",
      "\n",
      "Train Score: 0.9937369519832986\n",
      "Test Score: 0.7160751565762005\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tf', tf),\n",
    "    ('bg', bg)\n",
    "])\n",
    "\n",
    "params={\n",
    "    'tf__stop_words': [None, 'english'],\n",
    "    'tf__max_features': [None, 3000, 4000, 5000], # 2000\n",
    "    'tf__ngram_range': [(1, 1), (1, 2), (1, 3)], # (1, 5), (1, 4)\n",
    "    'bg__n_estimators': [5, 10, 50],\n",
    "    'bg__bootstrap_features': [True, False]\n",
    "}\n",
    "gs_bg_tf = GridSearchCV(pipe, param_grid=params, return_train_score=True)\n",
    "gs_bg_tf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearch Best Score:', gs_bg_tf.best_score_)\n",
    "print('GridSearch Best Params:',gs_bg_tf.best_params_)\n",
    "print()\n",
    "print('Train Score:', gs_bg_tf.score(X_train, y_train))\n",
    "print('Test Score:', gs_bg_tf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
